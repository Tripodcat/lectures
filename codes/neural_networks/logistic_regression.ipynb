{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_imgs(imgs,l1=4,l2=5,s1=6,s2=6):\n",
    "    \"\"\"    Plot images    \"\"\"\n",
    "    plt.rcParams['figure.figsize']=(s1,s2)\n",
    "    imgs=imgs.cpu().reshape([-1,28,28])\n",
    "    g, ax = plt.subplots(l1,l2)\n",
    "    for i in range(l1): \n",
    "        for j in range(l2):\n",
    "            a=i*l2+j\n",
    "            if(a>=imgs.shape[0]):\n",
    "                break\n",
    "            ax[i][j].imshow(imgs[a,:,:],cmap='summer')\n",
    "            ax[i][j].set_xticks([])\n",
    "            ax[i][j].set_yticks([])\n",
    "    plt.show()\n",
    "#show_imgs(data,2,10,10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "test_batch_size=100\n",
    "epochs=1000\n",
    "device=torch.device(\"cpu\")\n",
    "#device=torch.device(\"cuda:0\")\n",
    "data_path='../../data'\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device != torch.device('cpu') else {}\n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    datasets.MNIST(data_path, train=True,download=True, \n",
    "    transform=transforms.Compose([ transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=batch_size,\n",
    "    shuffle=False, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST(data_path, train=False,\n",
    "    transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,),\n",
    "    (0.3081,)) ])), batch_size=test_batch_size, shuffle=False, **kwargs)\n",
    "train_data=[]\n",
    "test_data=[]\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    train_data.append((data,target))\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    test_data.append((data,target))\n",
    "#print(train_data[0])\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_imgs(train_data[0][0],2,10,10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nin=784\n",
    "nout=10\n",
    "W=torch.randn(nin,nout,device=device) \n",
    "W.requires_grad=True\n",
    "bias = torch.randn(nout,device=device)\n",
    "bias.requres_grad=True\n",
    "print(train_data[0][0].shape)\n",
    "lr=0.001\n",
    "optimizer = torch.optim.Adam([W,bias], lr=lr, betas=(0.9, 0.999))\n",
    "print_bin = epochs/100\n",
    "for epoch in range(1, epochs + 1):\n",
    "    optimizer.zero_grad()\n",
    "    t1=time.time()\n",
    "    for batch_idx, (data, target) in enumerate(train_data):\n",
    "#        loss = F.cross_entropy(data.view(data.shape[0],-1)@W+bias.expand(data.shape[0],nout),target)\n",
    "        output=F.log_softmax(data.view(data.shape[0],-1)@W+bias.expand(data.shape[0],nout), dim=1)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_data:\n",
    "        output=F.log_softmax(data.view(data.shape[0],-1)@W+bias.expand(data.shape[0],nout), dim=1)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= 10000\n",
    "    correct /= 10000\n",
    "    if(epoch % print_bin==0):\n",
    "        print(\"#%d loss=%.3f test_loss=%.3f accuracy=%.3f time=%.3f\"%(epoch,loss,test_loss,correct,time.time()-t1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
